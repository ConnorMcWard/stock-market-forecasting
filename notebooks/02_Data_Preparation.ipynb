{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths dynamically\n",
    "BASE_DIR = os.getenv(\"DATA_DIR\", os.path.abspath(\"data\"))\n",
    "RAW_DATA_PATH = os.path.join(BASE_DIR, \"input\")\n",
    "PROCESSED_DATA_PATH = os.path.join(BASE_DIR, \"processed\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Get all CSV files\n",
    "csv_files = glob.glob(os.path.join(RAW_DATA_PATH, \"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {RAW_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrames efficiently using generators\n",
    "df_list = (pd.read_csv(file) for file in csv_files)\n",
    "full_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and encode static features\n",
    "static_features = full_df[['Ticker', 'Industry', 'Sub_Industry']].drop_duplicates(subset=[\"Ticker\"], keep=\"first\")\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_static = encoder.fit_transform(static_features[['Industry', 'Sub_Industry']])\n",
    "static_columns = list(encoder.get_feature_names_out(['Industry', 'Sub_Industry']))\n",
    "static_columns = [col.replace(\"Industry_\", \"Ind_\").replace(\"Sub_Industry_\", \"SubInd_\") for col in static_columns]\n",
    "static_features_df = pd.DataFrame(encoded_static, columns=static_columns)\n",
    "static_features_df['Ticker'] = static_features['Ticker'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single ticker\n",
    "def process_ticker_and_save(ticker_data):\n",
    "    ticker, ticker_df, static_vector, window_size = ticker_data\n",
    "    dynamic_features = [\"Adj Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "\n",
    "    # Avoid data leakage: fit on training set only\n",
    "    scaler = StandardScaler()\n",
    "    train_idx = int(len(ticker_df) * 0.8)  # Use 80% for training\n",
    "    train_data = ticker_df[dynamic_features].iloc[:train_idx]\n",
    "    scaler.fit(train_data)\n",
    "    \n",
    "    # Apply transformation\n",
    "    ticker_df[dynamic_features] = scaler.transform(ticker_df[dynamic_features])\n",
    "\n",
    "    # Create sliding windows\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(ticker_df) - window_size):\n",
    "        seq = ticker_df.iloc[i:i + window_size][dynamic_features].values\n",
    "        target = ticker_df.iloc[i + window_size][\"Adj Close\"]\n",
    "        static_repeated = np.tile(static_vector, (window_size, 1))\n",
    "        full_seq = np.hstack([seq, static_repeated])\n",
    "        sequences.append(full_seq)\n",
    "        targets.append(target)\n",
    "\n",
    "    # Save processed data\n",
    "    np.savez(os.path.join(PROCESSED_DATA_PATH, f\"{ticker}_data.npz\"), X=sequences, y=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelized processing\n",
    "def create_sliding_windows_parallel(ticker_groups, static_features_df, window_size=10):\n",
    "    ticker_data_list = []\n",
    "    for ticker, ticker_df in ticker_groups:\n",
    "        static_vector = static_features_df[static_features_df[\"Ticker\"] == ticker].drop(columns=[\"Ticker\"]).values.flatten()\n",
    "        ticker_data_list.append((ticker, ticker_df, static_vector, window_size))\n",
    "    \n",
    "    n_jobs = max(cpu_count() - 2, 1)  # Avoid overloading the CPU\n",
    "    with Pool(n_jobs) as pool:\n",
    "        pool.map(process_ticker_and_save, ticker_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    create_sliding_windows_parallel(full_df.groupby('Ticker'), static_features_df, window_size=10)\n",
    "    print(f\"Preprocessing complete! Processed data saved in '{PROCESSED_DATA_PATH}'.\")\n",
    "    \n",
    "    # Save static feature names to a JSON file\n",
    "    static_feature_names_path = os.path.join(PROCESSED_DATA_PATH, \"static_feature_names.json\")\n",
    "\n",
    "    with open(static_feature_names_path, \"w\") as f:\n",
    "        json.dump(static_columns, f)\n",
    "\n",
    "    print(f\"Static feature names saved to {static_feature_names_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
